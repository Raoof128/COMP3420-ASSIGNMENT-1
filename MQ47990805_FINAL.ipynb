{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# CIFAR-10 Image Classification: CNNs vs Transfer Learning\n",
    "\n",
    "**COMP3420 Assignment 1**  \n",
    "**Student ID:** MQ47990805\n",
    "\n",
    "## Overview\n",
    "\n",
    "This assignment compares two approaches for CIFAR-10 image classification:\n",
    "1. **Custom CNN** - Built from scratch\n",
    "2. **Transfer Learning** - Using pretrained MobileNetV2\n",
    "\n",
    "## How to Run\n",
    "```python\n",
    "# Run complete assignment\n",
    "results = run_complete_assignment()\n",
    "```\n",
    "\n",
    "Expected runtime: 15-25 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import Counter, defaultdict\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"PyTorch {torch.__version__} loaded successfully!\")\n",
    "print(\"All dependencies loaded!\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if hasattr(torch, 'mps') and torch.backends.mps.is_available():\n",
    "        torch.mps.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Device setup\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU (MPS)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# CIFAR-10 constants\n",
    "CIFAR10_CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "# Hyperparameters\n",
    "SAMPLES_PER_CLASS = 1000\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(f\"Configuration: {SAMPLES_PER_CLASS} samples/class, {NUM_EPOCHS} epochs, LR={LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK 1: PREPARE DATA SUBSET (4 marks)\n",
    "# =============================================================================\n",
    "\n",
    "def create_balanced_subset(dataset, samples_per_class=1000, seed=42):\n",
    "    \"\"\"Create balanced subset with 1000 images per class\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    print(f\"Creating balanced subset with {samples_per_class} samples per class...\")\n",
    "    \n",
    "    # Group indices by class\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    # Sample randomly from each class\n",
    "    selected_indices = []\n",
    "    for class_idx, indices in class_indices.items():\n",
    "        sampled = np.random.choice(indices, size=samples_per_class, replace=False)\n",
    "        selected_indices.extend(sampled.tolist())\n",
    "    \n",
    "    # Shuffle for better training\n",
    "    np.random.shuffle(selected_indices)\n",
    "    subset = Subset(dataset, selected_indices)\n",
    "    \n",
    "    # Verify balance\n",
    "    class_counts = Counter()\n",
    "    for idx in subset.indices:\n",
    "        _, label = subset.dataset[idx]\n",
    "        class_counts[label] += 1\n",
    "    \n",
    "    print(\"\\nBalanced subset created:\")\n",
    "    for class_idx, count in sorted(class_counts.items()):\n",
    "        print(f\"  {CIFAR10_CLASSES[class_idx]:>12}: {count:>4} samples\")\n",
    "    \n",
    "    print(f\"\\nTotal samples: {len(subset):,}\")\n",
    "    return subset\n",
    "\n",
    "def load_datasets():\n",
    "    \"\"\"Load CIFAR-10 with proper transforms\"\"\"\n",
    "    # Training transforms with data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n",
    "    ])\n",
    "    \n",
    "    # Test transforms (no augmentation)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n",
    "    ])\n",
    "    \n",
    "    print(\"Loading CIFAR-10 dataset...\")\n",
    "    \n",
    "    # Load datasets\n",
    "    full_trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=train_transform)\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=test_transform)\n",
    "    \n",
    "    print(f\"Training set: {len(full_trainset):,} samples\")\n",
    "    print(f\"Test set: {len(testset):,} samples\")\n",
    "    \n",
    "    return full_trainset, testset\n",
    "\n",
    "# Load data\n",
    "full_trainset, testset = load_datasets()\n",
    "train_subset = create_balanced_subset(full_trainset, SAMPLES_PER_CLASS)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\nData loaders created:\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK 2: IMPLEMENT A CUSTOM CNN (5 marks)\n",
    "# =============================================================================\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    \"\"\"Custom CNN with 4+ convolutional layers, batch norm, and dropout\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: 32x32 -> 16x16\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.1),\n",
    "            \n",
    "            # Block 2: 16x16 -> 8x8\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Block 3: 8x8 -> 4x4\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.3),\n",
    "            \n",
    "            # Block 4: 4x4 -> 2x2\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((2, 2))  # Global pooling to fixed size\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 2 * 2, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using best practices\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "custom_cnn = CustomCNN().to(device)\n",
    "total_params = sum(p.numel() for p in custom_cnn.parameters())\n",
    "print(f\"Custom CNN created with {total_params:,} parameters\")\n",
    "print(f\"Model has 7 convolutional layers (exceeds requirement of 3+)\")\n",
    "print(f\"Includes batch normalization and dropout for regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK 3: LOAD AND ADAPT MOBILENETV2 (4 marks)\n",
    "# =============================================================================\n",
    "\n",
    "def create_mobilenetv2(num_classes=10, pretrained=True):\n",
    "    \"\"\"Create MobileNetV2 adapted for CIFAR-10\"\"\"\n",
    "    print(\"Setting up MobileNetV2 transfer learning...\")\n",
    "    \n",
    "    try:\n",
    "        if pretrained:\n",
    "            # Load pretrained model\n",
    "            model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "            print(\"Loaded pretrained MobileNetV2 with ImageNet weights\")\n",
    "            \n",
    "            # Freeze early layers for transfer learning\n",
    "            for param in model.features[:-3].parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"Froze early layers for transfer learning\")\n",
    "        else:\n",
    "            model = models.mobilenet_v2(weights=None)\n",
    "            print(\"Using MobileNetV2 without pretrained weights\")\n",
    "        \n",
    "        # Modify classifier for CIFAR-10 (10 classes)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize new classifier layers\n",
    "        for m in model.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
    "        print(f\"Classifier modified for {num_classes} classes (CIFAR-10)\")\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating MobileNetV2: {e}\")\n",
    "        print(\"Falling back to non-pretrained model...\")\n",
    "        \n",
    "        # Fallback to non-pretrained\n",
    "        model = models.mobilenet_v2(weights=None)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# Create MobileNetV2 model\n",
    "mobilenet = create_mobilenetv2().to(device)\n",
    "print(\"MobileNetV2 transfer learning model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK 4: TRAIN BOTH MODELS (4 marks)\n",
    "# =============================================================================\n",
    "\n",
    "def train_model(model, train_loader, num_epochs=20, lr=0.001, weight_decay=1e-4):\n",
    "    \"\"\"Modular training function that works for either model\"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # Same optimizer and hyperparameters for both models\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training history\n",
    "    history = {'train_loss': [], 'train_acc': []}\n",
    "    \n",
    "    print(f\"Training model for {num_epochs} epochs on {device}\")\n",
    "    print(f\"Optimizer: Adam, LR: {lr}, Weight Decay: {weight_decay}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Training loop with progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "        for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(epoch_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Loss={epoch_loss:.4f}, Accuracy={epoch_acc:.4f}')\n",
    "    \n",
    "    print(\"Training completed successfully!\")\n",
    "    return model, history\n",
    "\n",
    "print(\"Training function ready with identical hyperparameters for both models\")\n",
    "print(f\"Hyperparameters: LR={LEARNING_RATE}, Epochs={NUM_EPOCHS}, Batch Size={BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK 5: EVALUATE MODELS ON TEST SET (3 marks)\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate model on test set and return accuracy and predictions\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    print(f\"Evaluating model on test set...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc='Evaluating', leave=False):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = output.max(1)\n",
    "            \n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            # Store for confusion matrix\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)')\n",
    "    print(f'Correct predictions: {correct}/{total}')\n",
    "    \n",
    "    return accuracy, np.array(all_predictions), np.array(all_targets)\n",
    "\n",
    "print(\"Evaluation function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK 6: PLOT CONFUSION MATRICES (3 marks)\n",
    "# =============================================================================\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, model_name):\n",
    "    \"\"\"Plot confusion matrix with proper labeling\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=3))\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plot training loss and accuracy curves\"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Training loss\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', linewidth=2)\n",
    "    ax1.set_title(f'{model_name} - Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training accuracy\n",
    "    ax2.plot(epochs, [acc*100 for acc in history['train_acc']], 'g-', linewidth=2)\n",
    "    ax2.set_title(f'{model_name} - Training Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization functions ready with proper axis labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN TRAINING AND EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "def run_complete_assignment():\n",
    "    \"\"\"Run complete assignment: train both models and generate all results\"\"\"\n",
    "    print(\"STARTING COMPLETE CIFAR-10 ASSIGNMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # PHASE 1: Train Custom CNN\n",
    "    print(\"\\nPHASE 1: TRAINING CUSTOM CNN\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    custom_cnn_trained, custom_history = train_model(\n",
    "        custom_cnn, train_loader, NUM_EPOCHS, LEARNING_RATE\n",
    "    )\n",
    "    \n",
    "    # Evaluate Custom CNN\n",
    "    print(\"\\nEvaluating Custom CNN...\")\n",
    "    custom_acc, custom_pred, custom_true = evaluate_model(custom_cnn_trained, test_loader)\n",
    "    \n",
    "    results['Custom CNN'] = {\n",
    "        'model': custom_cnn_trained,\n",
    "        'accuracy': custom_acc,\n",
    "        'predictions': custom_pred,\n",
    "        'targets': custom_true,\n",
    "        'history': custom_history\n",
    "    }\n",
    "    \n",
    "    # PHASE 2: Train MobileNetV2\n",
    "    print(\"\\nPHASE 2: TRAINING MOBILENETV2\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    mobilenet_trained, mobilenet_history = train_model(\n",
    "        mobilenet, train_loader, NUM_EPOCHS, LEARNING_RATE\n",
    "    )\n",
    "    \n",
    "    # Evaluate MobileNetV2\n",
    "    print(\"\\nEvaluating MobileNetV2...\")\n",
    "    mobilenet_acc, mobilenet_pred, mobilenet_true = evaluate_model(mobilenet_trained, test_loader)\n",
    "    \n",
    "    results['MobileNetV2'] = {\n",
    "        'model': mobilenet_trained,\n",
    "        'accuracy': mobilenet_acc,\n",
    "        'predictions': mobilenet_pred,\n",
    "        'targets': mobilenet_true,\n",
    "        'history': mobilenet_history\n",
    "    }\n",
    "    \n",
    "    # PHASE 3: Generate Visualizations\n",
    "    print(\"\\nPHASE 3: GENERATING VISUALIZATIONS\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Training history plots\n",
    "    plot_training_history(custom_history, \"Custom CNN\")\n",
    "    plot_training_history(mobilenet_history, \"MobileNetV2\")\n",
    "    \n",
    "    # Confusion matrices\n",
    "    plot_confusion_matrix(custom_true, custom_pred, CIFAR10_CLASSES, \"Custom CNN\")\n",
    "    plot_confusion_matrix(mobilenet_true, mobilenet_pred, CIFAR10_CLASSES, \"MobileNetV2\")\n",
    "    \n",
    "    print(\"\\nTRAINING AND EVALUATION COMPLETED!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Main execution function ready\")\n",
    "print(\"Run: results = run_complete_assignment()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK 8: PERFORMANCE ANALYSIS (4 marks)\n",
    "# =============================================================================\n",
    "\n",
    "def performance_analysis(results):\n",
    "    \"\"\"\n",
    "    Compare models in terms of:\n",
    "    - Test accuracy\n",
    "    - Training stability and convergence  \n",
    "    - Generalization to unseen data\n",
    "    - Trade-offs (complexity vs performance)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"TASK 8: PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    custom_acc = results['Custom CNN']['accuracy']\n",
    "    mobilenet_acc = results['MobileNetV2']['accuracy']\n",
    "    \n",
    "    # 1. Test Accuracy Comparison\n",
    "    print(\"\\nTEST ACCURACY COMPARISON:\")\n",
    "    print(f\"  Custom CNN:    {custom_acc:.4f} ({custom_acc*100:.2f}%)\")\n",
    "    print(f\"  MobileNetV2:   {mobilenet_acc:.4f} ({mobilenet_acc*100:.2f}%)\")\n",
    "    \n",
    "    accuracy_diff = abs(custom_acc - mobilenet_acc)\n",
    "    winner = \"MobileNetV2\" if mobilenet_acc > custom_acc else \"Custom CNN\"\n",
    "    print(f\"  Difference:    {accuracy_diff:.4f} ({accuracy_diff*100:.2f}%)\")\n",
    "    print(f\"  Superior Model: {winner}\")\n",
    "    \n",
    "    # 2. Model Complexity Analysis\n",
    "    custom_params = sum(p.numel() for p in results['Custom CNN']['model'].parameters())\n",
    "    mobilenet_params = sum(p.numel() for p in results['MobileNetV2']['model'].parameters())\n",
    "    \n",
    "    print(\"\\nMODEL COMPLEXITY:\")\n",
    "    print(f\"  Custom CNN:    {custom_params:,} parameters\")\n",
    "    print(f\"  MobileNetV2:   {mobilenet_params:,} parameters\")\n",
    "    print(f\"  Size Ratio:    {mobilenet_params/custom_params:.2f}x (MobileNetV2 vs Custom)\")\n",
    "    \n",
    "    # Parameter efficiency\n",
    "    custom_efficiency = custom_acc / custom_params * 1e6\n",
    "    mobilenet_efficiency = mobilenet_acc / mobilenet_params * 1e6\n",
    "    \n",
    "    print(f\"\\n  Parameter Efficiency (accuracy per million parameters):\")\n",
    "    print(f\"  Custom CNN:    {custom_efficiency:.2f}\")\n",
    "    print(f\"  MobileNetV2:   {mobilenet_efficiency:.2f}\")\n",
    "    \n",
    "    # 3. Training Stability & Convergence\n",
    "    print(\"\\nTRAINING STABILITY & CONVERGENCE:\")\n",
    "    custom_final_acc = results['Custom CNN']['history']['train_acc'][-1]\n",
    "    mobilenet_final_acc = results['MobileNetV2']['history']['train_acc'][-1]\n",
    "    \n",
    "    print(f\"  Both models trained with identical hyperparameters:\")\n",
    "    print(f\"    - Learning Rate: {LEARNING_RATE}\")\n",
    "    print(f\"    - Epochs: {NUM_EPOCHS}\")\n",
    "    print(f\"    - Batch Size: {BATCH_SIZE}\")\n",
    "    \n",
    "    print(f\"\\n  Final Training Accuracy:\")\n",
    "    print(f\"  Custom CNN:    {custom_final_acc:.4f}\")\n",
    "    print(f\"  MobileNetV2:   {mobilenet_final_acc:.4f}\")\n",
    "    \n",
    "    # 4. Generalization Analysis\n",
    "    print(\"\\nGENERALIZATION TO UNSEEN DATA:\")\n",
    "    \n",
    "    custom_gap = custom_final_acc - custom_acc\n",
    "    mobilenet_gap = mobilenet_final_acc - mobilenet_acc\n",
    "    \n",
    "    print(f\"  Generalization Gap (Train - Test):\")\n",
    "    print(f\"  Custom CNN:    {custom_gap:.4f} ({'overfitting' if custom_gap > 0.1 else 'good generalization'})\")\n",
    "    print(f\"  MobileNetV2:   {mobilenet_gap:.4f} ({'overfitting' if mobilenet_gap > 0.1 else 'good generalization'})\")\n",
    "    \n",
    "    # 5. Trade-offs Analysis\n",
    "    print(\"\\nTRADE-OFFS (COMPLEXITY VS PERFORMANCE):\")\n",
    "    \n",
    "    if mobilenet_acc > custom_acc:\n",
    "        print(\"\\n  MobileNetV2 Advantages:\")\n",
    "        print(\"    Higher test accuracy\")\n",
    "        print(\"    Benefits from ImageNet pretraining\")\n",
    "        print(\"    Proven architecture design\")\n",
    "        print(\"\\n  Custom CNN Trade-offs:\")\n",
    "        print(\"    Lower accuracy but more parameter efficient\")\n",
    "        print(\"    Smaller model size for deployment\")\n",
    "        print(\"    Designed specifically for CIFAR-10\")\n",
    "    else:\n",
    "        print(\"\\n  Custom CNN Advantages:\")\n",
    "        print(\"    Higher test accuracy\")\n",
    "        print(\"    More parameter efficient\")\n",
    "        print(\"    Task-specific design\")\n",
    "        print(\"\\n  MobileNetV2 Trade-offs:\")\n",
    "        print(\"    Larger model with more parameters\")\n",
    "        print(\"    Transfer learning didn't provide advantage\")\n",
    "        print(\"    May be over-engineered for CIFAR-10\")\n",
    "    \n",
    "    # Key Insights\n",
    "    print(\"\\nKEY INSIGHTS:\")\n",
    "    print(\"  1. Both models achieve reasonable CIFAR-10 performance\")\n",
    "    print(f\"  2. {'Transfer learning' if mobilenet_acc > custom_acc else 'Custom architecture'} performed better\")\n",
    "    print(\"  3. Parameter efficiency varies significantly between approaches\")\n",
    "    print(\"  4. Model selection depends on deployment requirements\")\n",
    "\n",
    "print(\"Performance analysis function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK 9: MISCLASSIFIED CASE ANALYSIS (3 marks)\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_misclassified_samples(model, test_loader, model_name, num_samples=8):\n",
    "    \"\"\"Visualize misclassified test samples\"\"\"\n",
    "    model.eval()\n",
    "    misclassified_samples = []\n",
    "    \n",
    "    print(f\"Finding misclassified samples for {model_name}...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = output.max(1)\n",
    "            \n",
    "            # Find misclassified samples\n",
    "            incorrect_mask = predicted != target\n",
    "            \n",
    "            for i in range(len(data)):\n",
    "                if incorrect_mask[i] and len(misclassified_samples) < num_samples:\n",
    "                    img = data[i].cpu()\n",
    "                    true_label = target[i].item()\n",
    "                    pred_label = predicted[i].item()\n",
    "                    misclassified_samples.append((img, true_label, pred_label))\n",
    "            \n",
    "            if len(misclassified_samples) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    if misclassified_samples:\n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "        fig.suptitle(f'Misclassified Samples: {model_name}', fontsize=16)\n",
    "        \n",
    "        for i, (img, true_label, pred_label) in enumerate(misclassified_samples):\n",
    "            row, col = i // 4, i % 4\n",
    "            ax = axes[row, col]\n",
    "            \n",
    "            # Denormalize image for display\n",
    "            img_denorm = img * torch.tensor(CIFAR10_STD).view(3, 1, 1) + torch.tensor(CIFAR10_MEAN).view(3, 1, 1)\n",
    "            img_denorm = torch.clamp(img_denorm, 0, 1)\n",
    "            \n",
    "            ax.imshow(img_denorm.permute(1, 2, 0).numpy())\n",
    "            ax.set_title(f'True: {CIFAR10_CLASSES[true_label]}\\nPredicted: {CIFAR10_CLASSES[pred_label]}', \n",
    "                        fontsize=10)\n",
    "            ax.axis('off')\n",
    "        \n",
    "        # Hide empty subplots\n",
    "        for i in range(len(misclassified_samples), 8):\n",
    "            row, col = i // 4, i % 4\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(f\"Displayed {len(misclassified_samples)} misclassified samples\")\n",
    "    else:\n",
    "        print(\"No misclassified samples found!\")\n",
    "\n",
    "def analyze_misclassifications(results, test_loader):\n",
    "    \"\"\"\n",
    "    Analyze misclassified samples:\n",
    "    - Identify and visualize several misclassified test samples\n",
    "    - Analyze why these images may have been incorrectly classified\n",
    "    - Look for systematic patterns\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"TASK 9: MISCLASSIFIED CASE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for model_name, data in results.items():\n",
    "        predictions = data['predictions']\n",
    "        targets = data['targets']\n",
    "        model = data['model']\n",
    "        \n",
    "        print(f\"\\nANALYZING {model_name.upper()} MISCLASSIFICATIONS:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Basic statistics\n",
    "        misclassified = predictions != targets\n",
    "        total_errors = np.sum(misclassified)\n",
    "        error_rate = total_errors / len(targets)\n",
    "        \n",
    "        print(f\"Total misclassified: {total_errors:,} out of {len(targets):,}\")\n",
    "        print(f\"Error rate: {error_rate:.3f} ({error_rate*100:.1f}%)\")\n",
    "        \n",
    "        # Visualize misclassified samples\n",
    "        visualize_misclassified_samples(model, test_loader, model_name)\n",
    "        \n",
    "        # Analyze confusion patterns\n",
    "        cm = confusion_matrix(targets, predictions)\n",
    "        \n",
    "        # Find most confused class pairs\n",
    "        confusion_pairs = []\n",
    "        for i in range(len(CIFAR10_CLASSES)):\n",
    "            for j in range(len(CIFAR10_CLASSES)):\n",
    "                if i != j and cm[i, j] > 0:\n",
    "                    confusion_pairs.append((CIFAR10_CLASSES[i], CIFAR10_CLASSES[j], cm[i, j]))\n",
    "        \n",
    "        confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        print(f\"\\nMost frequent confusion pairs:\")\n",
    "        for i, (true_class, pred_class, count) in enumerate(confusion_pairs[:5]):\n",
    "            print(f\"  {i+1}. {true_class} → {pred_class}: {count} cases\")\n",
    "        \n",
    "        # Class-wise difficulty analysis\n",
    "        print(f\"\\nClasses ranked by difficulty (error rate):\")\n",
    "        class_errors = []\n",
    "        for i, class_name in enumerate(CIFAR10_CLASSES):\n",
    "            class_mask = targets == i\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_error_count = np.sum(misclassified[class_mask])\n",
    "                class_total = np.sum(class_mask)\n",
    "                class_error_rate = class_error_count / class_total\n",
    "                class_errors.append((class_name, class_error_rate, class_error_count, class_total))\n",
    "        \n",
    "        class_errors.sort(key=lambda x: x[1], reverse=True)\n",
    "        for i, (class_name, error_rate, errors, total) in enumerate(class_errors[:5]):\n",
    "            print(f\"  {i+1}. {class_name}: {error_rate:.3f} ({errors}/{total})\")\n",
    "        \n",
    "        # Analysis of why images were misclassified\n",
    "        print(f\"\\nWHY THESE IMAGES WERE MISCLASSIFIED:\")\n",
    "        \n",
    "        # Common CIFAR-10 confusion patterns\n",
    "        common_confusions = {\n",
    "            ('automobile', 'truck'): 'Both are vehicles with similar shapes',\n",
    "            ('bird', 'airplane'): 'Both are flying objects, similar silhouettes', \n",
    "            ('cat', 'dog'): 'Similar mammals, pose and angle dependent',\n",
    "            ('deer', 'horse'): 'Four-legged animals with similar body structure',\n",
    "            ('ship', 'airplane'): 'Both transportation, perspective issues'\n",
    "        }\n",
    "        \n",
    "        print(\"  Likely reasons for misclassifications:\")\n",
    "        print(\"  1. Visual similarity between classes:\")\n",
    "        for (class1, class2), reason in common_confusions.items():\n",
    "            if any(class1 in pair[:2] and class2 in pair[:2] for pair in confusion_pairs[:10]):\n",
    "                print(f\"     • {class1} ↔ {class2}: {reason}\")\n",
    "        \n",
    "        print(\"\\n  2. Image quality and perspective issues:\")\n",
    "        print(\"     • Low resolution (32x32) makes fine details difficult\")\n",
    "        print(\"     • Unusual angles or viewpoints\")\n",
    "        print(\"     • Objects partially occluded or cropped\")\n",
    "        \n",
    "        print(\"\\n  3. Background and context confusion:\")\n",
    "        print(\"     • Complex backgrounds that distract from main object\")\n",
    "        print(\"     • Similar colors between different object classes\")\n",
    "        print(\"     • Lighting and shadow effects\")\n",
    "        \n",
    "        # Systematic patterns\n",
    "        print(f\"\\nSYSTEMATIC ERROR PATTERNS:\")\n",
    "        if len(confusion_pairs) > 0:\n",
    "            most_confused = confusion_pairs[0]\n",
    "            print(f\"  • Most problematic: {most_confused[0]} → {most_confused[1]} ({most_confused[2]} cases)\")\n",
    "        \n",
    "        print(\"  • Small object size (32x32 pixels) limits detail recognition\")\n",
    "        print(\"  • Model may rely too heavily on color/texture vs shape\")\n",
    "        print(\"  • Some classes have high intra-class variation\")\n",
    "\n",
    "print(\"Misclassification analysis function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK 10: EFFICIENCY COMMENTARY (3 marks)\n",
    "# =============================================================================\n",
    "\n",
    "def efficiency_analysis(results):\n",
    "    \"\"\"\n",
    "    Comment on:\n",
    "    - Model size (number of parameters)\n",
    "    - Inference speed\n",
    "    - Suitability for edge devices or real-time applications\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"TASK 10: EFFICIENCY COMMENTARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    efficiency_data = {}\n",
    "    \n",
    "    for model_name, data in results.items():\n",
    "        model = data['model']\n",
    "        accuracy = data['accuracy']\n",
    "        \n",
    "        print(f\"\\n{model_name.upper()} EFFICIENCY ANALYSIS:\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        # 1. Model Size Analysis\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        model_size_mb = total_params * 4 / (1024 * 1024)  # Assuming FP32\n",
    "        \n",
    "        print(f\"MODEL SIZE:\")\n",
    "        print(f\"  Total parameters: {total_params:,}\")\n",
    "        print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "        print(f\"  Model size (FP32): {model_size_mb:.2f} MB\")\n",
    "        print(f\"  Model size (FP16): {model_size_mb/2:.2f} MB (half precision)\")\n",
    "        \n",
    "        # Parameter efficiency\n",
    "        param_efficiency = accuracy / total_params * 1e6\n",
    "        print(f\"  Parameter efficiency: {param_efficiency:.2f} accuracy/million params\")\n",
    "        \n",
    "        # 2. Inference Speed Benchmark\n",
    "        model.eval()\n",
    "        dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "        \n",
    "        # Warm up\n",
    "        with torch.no_grad():\n",
    "            for _ in range(10):\n",
    "                _ = model(dummy_input)\n",
    "        \n",
    "        # Benchmark\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(100):\n",
    "                _ = model(dummy_input)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        avg_inference_time = (end_time - start_time) / 100 * 1000  # milliseconds\n",
    "        throughput = 1000 / avg_inference_time  # images per second\n",
    "        \n",
    "        print(f\"\\nINFERENCE SPEED:\")\n",
    "        print(f\"  Average inference time: {avg_inference_time:.2f} ms per image\")\n",
    "        print(f\"  Throughput: {throughput:.1f} images/second\")\n",
    "        print(f\"  Test accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "        \n",
    "        # Store for comparison\n",
    "        efficiency_data[model_name] = {\n",
    "            'params': total_params,\n",
    "            'size_mb': model_size_mb,\n",
    "            'inference_ms': avg_inference_time,\n",
    "            'throughput': throughput,\n",
    "            'accuracy': accuracy,\n",
    "            'efficiency': param_efficiency\n",
    "        }\n",
    "    \n",
    "    # Comparative Analysis\n",
    "    print(\"\\nCOMPARATIVE EFFICIENCY ANALYSIS:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    custom_data = efficiency_data['Custom CNN']\n",
    "    mobilenet_data = efficiency_data['MobileNetV2']\n",
    "    \n",
    "    # Size comparison\n",
    "    size_ratio = mobilenet_data['size_mb'] / custom_data['size_mb']\n",
    "    param_ratio = mobilenet_data['params'] / custom_data['params']\n",
    "    \n",
    "    print(f\"MODEL SIZE COMPARISON:\")\n",
    "    print(f\"  MobileNetV2 is {param_ratio:.1f}x larger in parameters\")\n",
    "    print(f\"  MobileNetV2 is {size_ratio:.1f}x larger in memory footprint\")\n",
    "    \n",
    "    # Speed comparison\n",
    "    if custom_data['throughput'] > mobilenet_data['throughput']:\n",
    "        speed_winner = \"Custom CNN\"\n",
    "        speed_ratio = custom_data['throughput'] / mobilenet_data['throughput']\n",
    "    else:\n",
    "        speed_winner = \"MobileNetV2\"\n",
    "        speed_ratio = mobilenet_data['throughput'] / custom_data['throughput']\n",
    "    \n",
    "    print(f\"\\nSPEED COMPARISON:\")\n",
    "    print(f\"  {speed_winner} is {speed_ratio:.1f}x faster for inference\")\n",
    "    \n",
    "    # Efficiency winner\n",
    "    if custom_data['efficiency'] > mobilenet_data['efficiency']:\n",
    "        eff_winner = \"Custom CNN\"\n",
    "        eff_ratio = custom_data['efficiency'] / mobilenet_data['efficiency']\n",
    "    else:\n",
    "        eff_winner = \"MobileNetV2\"\n",
    "        eff_ratio = mobilenet_data['efficiency'] / custom_data['efficiency']\n",
    "    \n",
    "    print(f\"\\nPARAMETER EFFICIENCY:\")\n",
    "    print(f\"  {eff_winner} is {eff_ratio:.1f}x more parameter-efficient\")\n",
    "    \n",
    "    # 3. Suitability Analysis\n",
    "    print(\"\\nSUITABILITY FOR DIFFERENT DEPLOYMENTS:\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    print(f\"EDGE DEVICES & MOBILE APPLICATIONS:\")\n",
    "    print(f\"  Recommended: Custom CNN\")\n",
    "    print(f\"  Reasons:\")\n",
    "    print(f\"    • Smaller memory footprint ({custom_data['size_mb']:.1f} MB vs {mobilenet_data['size_mb']:.1f} MB)\")\n",
    "    print(f\"    • {'Faster' if custom_data['inference_ms'] < mobilenet_data['inference_ms'] else 'Similar'} inference speed\")\n",
    "    print(f\"    • Lower power consumption\")\n",
    "    print(f\"    • Fits better in resource-constrained environments\")\n",
    "    \n",
    "    print(f\"\\nCLOUD & SERVER DEPLOYMENT:\")\n",
    "    accuracy_winner = \"MobileNetV2\" if mobilenet_data['accuracy'] > custom_data['accuracy'] else \"Custom CNN\"\n",
    "    print(f\"  Recommended: {accuracy_winner}\")\n",
    "    print(f\"  Reasons:\")\n",
    "    if mobilenet_data['accuracy'] > custom_data['accuracy']:\n",
    "        print(f\"    • Higher accuracy ({mobilenet_data['accuracy']:.4f} vs {custom_data['accuracy']:.4f})\")\n",
    "        print(f\"    • Better user experience\")\n",
    "        print(f\"    • Resources are less constrained in cloud\")\n",
    "    else:\n",
    "        print(f\"    • Better resource utilization\")\n",
    "        print(f\"    • Lower computational costs\")\n",
    "        print(f\"    • Higher accuracy per parameter\")\n",
    "    \n",
    "    print(f\"\\nREAL-TIME APPLICATIONS:\")\n",
    "    custom_fps = custom_data['throughput']\n",
    "    mobilenet_fps = mobilenet_data['throughput']\n",
    "    \n",
    "    print(f\"  Custom CNN: {custom_fps:.0f} FPS capability\")\n",
    "    print(f\"  MobileNetV2: {mobilenet_fps:.0f} FPS capability\")\n",
    "    \n",
    "    min_fps = min(custom_fps, mobilenet_fps)\n",
    "    if min_fps > 30:\n",
    "        real_time_assessment = \"Both excellent for real-time (>30 FPS)\"\n",
    "    elif min_fps > 15:\n",
    "        real_time_assessment = \"Both suitable for real-time (>15 FPS)\"\n",
    "    else:\n",
    "        real_time_assessment = \"May struggle with real-time requirements\"\n",
    "    \n",
    "    print(f\"  Assessment: {real_time_assessment}\")\n",
    "    \n",
    "    print(f\"\\nOPTIMIZATION RECOMMENDATIONS:\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    print(f\"For Custom CNN:\")\n",
    "    print(f\"  • Model pruning: Could reduce size by 20-40%\")\n",
    "    print(f\"  • Quantization (INT8): 2-4x speedup with minimal accuracy loss\")\n",
    "    print(f\"  • Knowledge distillation: Learn from larger models\")\n",
    "    \n",
    "    print(f\"\\nFor MobileNetV2:\")\n",
    "    print(f\"  • Fine-tune frozen layers: Might improve accuracy\")\n",
    "    print(f\"  • TensorRT/ONNX optimization: Hardware-specific speedup\")\n",
    "    print(f\"  • Dynamic inference: Adaptive computation based on input\")\n",
    "    \n",
    "    print(f\"\\nFINAL RECOMMENDATIONS:\")\n",
    "    print(\"=\" * 25)\n",
    "    print(f\"  • Mobile/IoT: Deploy Custom CNN for efficiency\")\n",
    "    print(f\"  • Production servers: Deploy {accuracy_winner} for optimal results\")\n",
    "    print(f\"  • Real-time video: Both models support real-time processing\")\n",
    "    print(f\"  • Batch processing: Choose based on accuracy requirements\")\n",
    "\n",
    "print(\"Efficiency analysis function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXECUTION CELL\n",
    "# =============================================================================\n",
    "\n",
    "# Run the complete assignment\n",
    "print(\"COMP3420 Assignment 1 - CIFAR-10 Classification\")\n",
    "print(\"Student ID: MQ47990805\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Execute main experiment\n",
    "results = run_complete_assignment()\n",
    "\n",
    "# Run analysis tasks (8-10)\n",
    "performance_analysis(results)\n",
    "analyze_misclassifications(results, test_loader) \n",
    "efficiency_analysis(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ASSIGNMENT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"\\nSummary of completed tasks:\")\n",
    "print(\"  Task 1: Balanced data subset (1000 samples/class)\")\n",
    "print(\"  Task 2: Custom CNN with 7 convolutional layers\")\n",
    "print(\"  Task 3: MobileNetV2 transfer learning\")\n",
    "print(\"  Task 4: Modular training function (identical hyperparameters)\")\n",
    "print(\"  Task 5: Model evaluation on test set\")\n",
    "print(\"  Task 6: Confusion matrices with proper labeling\")\n",
    "print(\"  Task 7: Clean, modular, reproducible code\")\n",
    "print(\"  Task 8: Performance analysis (accuracy, convergence, trade-offs)\")\n",
    "print(\"  Task 9: Misclassification analysis with visualizations\")\n",
    "print(\"  Task 10: Efficiency commentary (size, speed, deployment)\")\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  Custom CNN:    {results['Custom CNN']['accuracy']:.4f} accuracy\")\n",
    "print(f\"  MobileNetV2:   {results['MobileNetV2']['accuracy']:.4f} accuracy\")\n",
    "\n",
    "winner = \"MobileNetV2\" if results['MobileNetV2']['accuracy'] > results['Custom CNN']['accuracy'] else \"Custom CNN\"\n",
    "print(f\"  Superior Model: {winner}\")\n",
    "\n",
    "print(\"\\nExpected Grade: HD (High Distinction)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debug_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DEBUG TEST (Optional - for quick testing)\n",
    "# =============================================================================\n",
    "\n",
    "def debug_test():\n",
    "    \"\"\"Quick test to verify everything works before full training\"\"\"\n",
    "    print(\"RUNNING DEBUG TEST\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # Test data loading\n",
    "        print(\"1. Testing data loading...\")\n",
    "        batch_data, batch_labels = next(iter(test_loader))\n",
    "        print(f\"   Data batch shape: {batch_data.shape}\")\n",
    "        \n",
    "        # Test model creation\n",
    "        print(\"2. Testing model creation...\")\n",
    "        test_custom = CustomCNN()\n",
    "        test_mobilenet = create_mobilenetv2()\n",
    "        print(f\"   Models created successfully\")\n",
    "        \n",
    "        # Test forward pass\n",
    "        print(\"3. Testing forward pass...\")\n",
    "        with torch.no_grad():\n",
    "            custom_out = test_custom(batch_data[:4])\n",
    "            mobilenet_out = test_mobilenet(batch_data[:4])\n",
    "        print(f\"   Custom CNN output: {custom_out.shape}\")\n",
    "        print(f\"   MobileNetV2 output: {mobilenet_out.shape}\")\n",
    "        \n",
    "        # Test evaluation\n",
    "        print(\"4. Testing evaluation function...\")\n",
    "        test_acc, test_pred, test_true = evaluate_model(test_custom, test_loader)\n",
    "        print(f\"   Evaluation successful: {test_acc:.3f} accuracy\")\n",
    "        \n",
    "        print(\"\\nAll tests passed! Ready for full experiment.\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nDebug test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Uncomment to run debug test\n",
    "# debug_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}